{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4358d8",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only install the following libraries if you dont have it, otherwise leave it commented out\n",
    "\n",
    "#!conda install -c anaconda natsort --yes\n",
    "#!conda install -c anaconda xlrd --yes\n",
    "\n",
    "#!pip install natsort --user\n",
    "#!pip install xlrd --user\n",
    "#!pip install pycaret[full] --user\n",
    "#!pip install mlflow --user\n",
    "#!pip install tune-sklearn ray[tune] --user\n",
    "#!pip install optuna -- user\n",
    "#!pip install hyperopt --user\n",
    "#!pip install redis --user\n",
    "\n",
    "# General Libraries\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "sns.set()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn Liraries\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta, date \n",
    "start = time.time()\n",
    "%matplotlib inline\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "# Forces the print statement to show everything and not truncate\n",
    "# np.set_printoptions(threshold=sys.maxsize) \n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receive Data\n",
    "#dir_name = r'C:\\Users\\kswaminathan\\OneDrive\\01_KannaLibrary\\15_Analogs'\n",
    "dir_name = r'C:\\Users\\mkumar\\Documents\\GitHub\\@Papers\\SPE2022\\Final\\1_TORIS_MODEL'\n",
    "filename_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7884ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_excel(\"dfssoil.xlsx\", thousands=',', skiprows = skiprows)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c2c0d",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy\n",
    "df_train_test_set=df.copy()\n",
    "\n",
    "Feature = df_train_test_set[[\n",
    "    'Lithology Code', \n",
    "    'Well Spacing',\n",
    "    'Net Pay Pay',\n",
    "    'Gross Pay',\n",
    "    'Porosity', \n",
    "    'Swi',\n",
    "    'Oil FVFi',\n",
    "    'Temp',\n",
    "    'Permeability', \n",
    "    'API Gravity', \n",
    "    'Viscosity',\n",
    "    'OOIP',\n",
    "    'Initial GOR',\n",
    "    'Pressure Initial',\n",
    "    'Fractured Faulted',\n",
    "    'Shale Breaks',\n",
    "    'Major Gas Cap',\n",
    "    'Geologic Play',\n",
    "    'Deposition System',\n",
    "    'Diagenetic Overprint',\n",
    "    'Structural Comp',\n",
    "    'Heterogeniety',\n",
    "    'Trap Type'\n",
    "]]\n",
    "x=Feature\n",
    "\n",
    "y = df_train_test_set['URF'].values\n",
    "\n",
    "print(x.head())\n",
    "print(y[0:5])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d91c3",
   "metadata": {},
   "source": [
    "### Train-Test Split 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.3\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(\n",
    "            x, y, test_size = test_size, random_state = random_state\n",
    ")\n",
    "\n",
    "print('Train Set: ', x_train.shape, y_train.shape)\n",
    "print(x_train['Permeability'][0:5])\n",
    "print('Test Set: ', x_test.shape, y_test.shape)\n",
    "print(x_test['Permeability'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e34227",
   "metadata": {},
   "source": [
    "### Normalization as per Pycaret z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ad533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/data-normalization-with-pandas-and-scikit-learn-7c1cc6ed6475\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = preprocessing.StandardScaler().fit(x_train).transform(x_train)\n",
    "X_test = preprocessing.StandardScaler().fit(x_test).transform(x_test)\n",
    "print('Standardization X Training Set: ', X_train[0:5])\n",
    "print('Standardization X Testing Set: ', X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d214a",
   "metadata": {},
   "source": [
    "### Transformation as per Pycaret 'yeo johnson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9943f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "Xt_train = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True).fit(X_train).transform(X_train)\n",
    "Xt_test = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True).fit(X_test).transform(X_test)\n",
    "print('Transformed X Training Set: ', Xt_train[0:5])\n",
    "print('Transformed X Testing Set: ', Xt_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbb47d",
   "metadata": {},
   "source": [
    "## Note that Ignore Low Variance and Remove Outliers is not implemented as it is assumed it will not make a significant difference to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f956955",
   "metadata": {},
   "source": [
    "#### K-fold and grid search CV on 2 variables only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regressor\n",
    "# win_rf=RandomForestRegressor(n_estimators=100, criterion=\"mse\", max_depth=None, min_samples_split=2)\n",
    "# win_rf.fit(Xt_train, y_train)\n",
    "# yhat_rf = win_rf.predict(Xt_test)\n",
    "\n",
    "def rfr_model(X, y, Xt):\n",
    "# Perform Grid-Search\n",
    "# bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "# max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "# max_samples=None, min_impurity_decrease=0.0,\n",
    "# min_impurity_split=None, min_samples_leaf=1,\n",
    "# min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "# n_estimators=100, n_jobs=-1, oob_score=False,\n",
    "# random_state=42, verbose=0, warm_start=False\n",
    "\n",
    "    # Create Base Model\n",
    "    rfr = RandomForestRegressor(\n",
    "        bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "        max_depth=None,\n",
    "        max_features='auto', max_leaf_nodes=None,\n",
    "        max_samples=None, min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None, min_samples_leaf=1,\n",
    "        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "        n_estimators=100, \n",
    "        n_jobs=-1, oob_score=False,\n",
    "        random_state=42, verbose=0, warm_start=False\n",
    "    )\n",
    "    \n",
    "    rfr.fit(X, y)\n",
    "    predictions1 = rfr.predict(Xt)\n",
    "\n",
    "    # Do Grid search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=rfr,\n",
    "        param_grid={\n",
    "            'max_depth': range(3,7),\n",
    "            'n_estimators': (10, 50, 100, 1000),\n",
    "        },\n",
    "        cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    \n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "    # Create K-fold Grid Model\n",
    "    rfr2 = RandomForestRegressor(\n",
    "        bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        max_features='auto', max_leaf_nodes=None,\n",
    "        max_samples=None, min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None, min_samples_leaf=1,\n",
    "        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "        n_estimators=best_params[\"n_estimators\"], \n",
    "        n_jobs=-1, oob_score=False,\n",
    "        random_state=42, verbose=0, warm_start=False\n",
    "    )    \n",
    "  \n",
    "    rfr2.fit(X, y)\n",
    "    # Perform K-Fold CV\n",
    "    scores = cross_val_score(rfr2, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "        \n",
    "    # Predict\n",
    "    #predictions = cross_val_predict(rfr, X, y, cv=10)\n",
    "    predictions2 = rfr2.predict(Xt)\n",
    "    \n",
    "    return scores, predictions1, predictions2, rfr, rfr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9663e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rf_grid, yhat_rf, yhat_rf_grid, rfr, rfr_grid = rfr_model(Xt_train, y_train, Xt_test)\n",
    "print(\"MAE Score\", win_rf_grid)\n",
    "\n",
    "errors1 = abs(yhat_rf - y_test)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors1), 2), 'V/V')\n",
    "mape1 = np.mean(100 * (errors1 / y_test))\n",
    "accuracy1 = 100 - mape1\n",
    "print('Accuracy:', round(accuracy1, 2), '%.')\n",
    "\n",
    "errors2 = abs(yhat_rf_grid - y_test)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors2), 2), 'V/V')\n",
    "mape2 = np.mean(100 * (errors2 / y_test))\n",
    "accuracy2 = 100 - mape2\n",
    "print('Accuracy:', round(accuracy2, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c887f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_test\n",
    "b = yhat_rf_grid\n",
    "c = yhat_rf\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(a, b, color='blue')\n",
    "plt.scatter(a, c, color='green')\n",
    "plt.plot(a, a, color = 'red', label = 'x=y')\n",
    "plt.xlabel(\"Recovery Factor (%)\", size=14)\n",
    "plt.ylabel(\"Evaluated Recovery Factor (%)\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d25f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfblind = pd.read_excel(\"BlindTest_SSOIL.xlsx\", thousands=',', skiprows = skiprows)\n",
    "#dfblind = dfblind.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "dfblind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4847ba4",
   "metadata": {},
   "source": [
    "### Blind Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_df = dfblind.copy()\n",
    "blind_df.drop(['URF'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11383873",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_df_norm = preprocessing.StandardScaler().fit(blind_df).transform(blind_df)\n",
    "blind_df_norm_tran = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True).fit(blind_df_norm).transform(blind_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9740194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfblind['URF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feefe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfr.predict(blind_df_norm_tran)\n",
    "print(predictions)\n",
    "\n",
    "predictions_grid = rfr_grid.predict(blind_df_norm_tran)\n",
    "print(predictions_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dfblind['URF']\n",
    "b = predictions\n",
    "c = predictions_grid\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(a, b, color='blue')\n",
    "plt.scatter(a, c, color='green')\n",
    "plt.plot(a, a, color = 'red', label = 'x=y')\n",
    "plt.xlabel(\"Recovery Factor (%)\", size=14)\n",
    "plt.ylabel(\"Evaluated Recovery Factor (%)\", size=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
